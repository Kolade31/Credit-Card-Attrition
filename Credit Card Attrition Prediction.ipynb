{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToolBox Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4484\\888236468.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#Models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "#Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Model evaluation\n",
    "from sklearn.metrics import *\n",
    "\n",
    "#Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\USER1\\Desktop\\credit_card_churn.csv')\n",
    "# Letâ€™s observe the shape of our datasets.\n",
    "print('train data shape :',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking first five rows in dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking last five rows in dataset\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing dataset information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing statistical description of dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values in train set\n",
    "print(f'Any NaN values? {data.isna().values.any()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates values in train set\n",
    "print(f'Any duplicates? {data.duplicated().values.any()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping irrelevant columns\n",
    "data = data.drop(\n",
    "['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'],\n",
    "axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing a distribution of numerical columns in the dataset\n",
    "data.hist(figsize = (20,11), color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking percentage of target outcomes\n",
    "data['Attrition_Flag'].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing barplot of attrition flag\n",
    "data['Attrition_Flag'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing barplot of educational level\n",
    "data['Education_Level'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Income_Category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing barplot of card category\n",
    "data['Card_Category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing barplot of marital status\n",
    "data['Marital_Status'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing barplot of gender\n",
    "data['Gender'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of credit limit-age distribution\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.boxplot(data=data,y='Credit_Limit',x='Customer_Age')\n",
    "plt.xlabel('Customers Age')\n",
    "plt.ylabel('Credit_Limit')\n",
    "plt.title('Credit Limit-Age Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of credit limit-gender distribution\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.boxplot(data=data,y='Credit_Limit',x='Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Credit_Limit')\n",
    "plt.title('Credit Limit-Gender Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of credit limit-income distribution\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.boxplot(data=data,y='Credit_Limit',x='Income_Category')\n",
    "plt.xlabel('Income_Category')\n",
    "plt.ylabel('Credit_Limit')\n",
    "plt.title('Credit Limit-Income Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of credit limit-marital status distribution\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.boxplot(data=data,y='Credit_Limit',x='Marital_Status')\n",
    "plt.xlabel('Marital_Status')\n",
    "plt.ylabel('Credit_Limit')\n",
    "plt.title('Credit Limit-Marital_Status Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of credit limit-card category distribution\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.boxplot(data=data,y='Credit_Limit',x='Card_Category')\n",
    "plt.xlabel('Income_Category')\n",
    "plt.ylabel('Credit_Limit')\n",
    "plt.title('Credit Limit-Card_Category Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crosstable of gender and attrition flag columns\n",
    "pd.crosstab(data['Gender'], data['Attrition_Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_bar = pd.crosstab(data['Gender'], data['Attrition_Flag'])\n",
    "gen_bar.div(gen_bar.sum(axis = 1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (7,7))\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crosstable of education level and attrition flag columns\n",
    "pd.crosstab(data['Education_Level'], data['Attrition_Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_bar = pd.crosstab(data['Education_Level'], data['Attrition_Flag'])\n",
    "edu_bar.div(edu_bar.sum(axis = 1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (8,8))\n",
    "plt.xlabel('Education_Level')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crosstable of marital status and attrition flag columns\n",
    "pd.crosstab(data['Marital_Status'], data['Attrition_Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_bar = pd.crosstab(data['Marital_Status'], data['Attrition_Flag'])\n",
    "mar_bar.div(mar_bar.sum(axis = 1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (8,8))\n",
    "plt.xlabel('Education_Level')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crosstable of card category and attrition flag columns\n",
    "pd.crosstab(data['Card_Category'], data['Attrition_Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_bar = pd.crosstab(data['Card_Category'], data['Attrition_Flag'])\n",
    "car_bar.div(car_bar.sum(axis = 1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (8,8))\n",
    "plt.xlabel('Education_Level')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crosstable of income category and attrition flag columns\n",
    "pd.crosstab(data['Income_Category'], data['Attrition_Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_bar = pd.crosstab(data['Income_Category'], data['Attrition_Flag'])\n",
    "inc_bar.div(inc_bar.sum(axis = 1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (8,8))\n",
    "plt.xlabel('Education_Level')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical columns\n",
    "le = LabelEncoder()\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "data['Education_Level'] = le.fit_transform(data['Education_Level'])\n",
    "data['Marital_Status'] = le.fit_transform(data['Marital_Status'])\n",
    "data['Income_Category'] = le.fit_transform(data['Income_Category'])\n",
    "data['Card_Category'] = le.fit_transform(data['Card_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding target outcome\n",
    "data['Attrition_Flag'] = data['Attrition_Flag'].map({'Existing Customer' : 1,'Attrited Customer':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlations among features in dataset\n",
    "correlation = data.corr()\n",
    "print(correlation['Attrition_Flag'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap of correlations in dataset\n",
    "plt.figure(figsize = (22,10))\n",
    "sns.heatmap(correlation, annot=True,cmap='RdYlBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping irrelevant columns\n",
    "data = data.drop(columns = ['CLIENTNUM','Total_Trans_Ct','Months_on_book',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the target & predictor variables \n",
    "X = data.drop('Attrition_Flag', axis = 1)\n",
    "y = data['Attrition_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the dataframe using SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.6)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting target and predictor variables into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report of model\n",
    "print('Report:', classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix of logistic regression\n",
    "cm = confusion_matrix(y_test, prediction, labels=[1, 0])\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Positive:1', 'Negative:0'], index=['Positive:1', 'Negative:0'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.title(\"The Confusion Matrix of the Predictions\", y = 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report of model\n",
    "print('Report:', classification_report(y_test, prediction_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confudion matrix of decision tree classifier\n",
    "cm_dt = confusion_matrix(y_test, prediction_clf, labels=[1, 0])\n",
    "cm_matrix_dt = pd.DataFrame(data=cm_dt, columns=['Positive:1', 'Negative:0'], index=['Positive:1', 'Negative:0'])\n",
    "sns.heatmap(cm_matrix_dt, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.title(\"The Confusion Matrix of the Predictions\", y = 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "prediction_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report of model\n",
    "print('Report:', classification_report(y_test, prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix of random forest classifier\n",
    "cm_rf = confusion_matrix(y_test, prediction_rf, labels=[1, 0])\n",
    "cm_matrix_rf = pd.DataFrame(data=cm_rf, columns=['Positive:1', 'Negative:0'], index=['Positive:1', 'Negative:0'])\n",
    "sns.heatmap(cm_matrix_rf, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.title(\"The Confusion Matrix of the Predictions\", y = 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model,data):\n",
    "    return pd.DataFrame({'Columns': X.columns,'importance':model.feature_importances_}).sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(rf_model,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting feature importances\n",
    "feature_importance(rf_model,X_train).plot('Columns','importance','barh',\n",
    "                                    figsize=(12,8),legend=False)\n",
    "plt.title('Feature Importance based on Random Forest Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d65c2938b4c1e10a48722e4586d894435681ddf28ba4bae8b5a152333d7d2122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
